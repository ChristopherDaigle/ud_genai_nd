{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda95e5d-9d96-4365-889d-cd01079832c4",
   "metadata": {},
   "source": [
    "# PyTorch Training Loops\n",
    "\n",
    "A PyTorch training loop is an essential part of building a neural network model, which helps us teach the computer how to make predictions or decisions based on data. By using this loop, we gradually improve our model's accuracy through a process of learning from its mistakes and adjusting.\n",
    "\n",
    "[PyTorch Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)\n",
    "\n",
    "## Technical Terms Explained:\n",
    "**Training Loop:** The cycle that a neural network goes through many times to learn from the data by making predictions, checking errors, and improving itself.\n",
    "\n",
    "**Batches:** Batches are small, evenly divided parts of data that the AI looks at and learns from each step of the way.\n",
    "\n",
    "**Epochs:** A complete pass through the entire training dataset. The more epochs, the more the computer goes over the material to learn.\n",
    "\n",
    "**Loss functions:** They measure how well a model is performing by calculating the difference between the model's predictions and the actual results.\n",
    "\n",
    "**Optimizer:** Part of the neural network's brain that makes decisions on how to change the network to get better at its job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37bbc8fd-7281-4496-8d93-0f9d92d0fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69607c1e-4888-408d-929e-2fd1bb6475a0",
   "metadata": {},
   "source": [
    "Below, we will make a model that \"predicts\" continuous values that are just the addition of two other values. **This is a bad use of a statistical model, but it can be an example for understanding the architecture and applying the tool.** At the end of our training loop, the model will not *know* how to add something like $3 + 7$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56012ef-6f4a-4881-9e87-c3baa20e0e0d",
   "metadata": {},
   "source": [
    "Create a Number Sum Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b0a622-9cfc-427a-a8d4-af16565ac982",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberSumDataset(Dataset):\n",
    "    def __init__(self, data_range:tuple=(1,10)):\n",
    "        \"\"\"\n",
    "        Create a list of number from data_range[0] to data_range[1]\n",
    "        \"\"\"\n",
    "        self.numbers = list(range(data_range[0], data_range[1]))\n",
    "        return\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Return a row of data with num0, num1, and the sum of them where num0 and num1 take values based on the index argument\n",
    "        \"\"\"\n",
    "        num0 = float(self.numbers[index // len(self.numbers)])\n",
    "        num1 = float(self.numbers[index % len(self.numbers)])\n",
    "        return torch.tensor([num0, num1]), torch.tensor([num0 + num1])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the square of the number of elements\n",
    "        \"\"\"\n",
    "        return len(self.numbers) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1723a43f-212d-45bf-ad12-ec1a8de6e0b8",
   "metadata": {},
   "source": [
    "Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb86f290-5217-4ff9-b2ab-575ceb10a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9801\n",
      "(tensor([1., 1.]), tensor([2.]))\n",
      "(tensor([1., 2.]), tensor([3.]))\n",
      "(tensor([1., 3.]), tensor([4.]))\n",
      "(tensor([1., 4.]), tensor([5.]))\n",
      "(tensor([1., 5.]), tensor([6.]))\n"
     ]
    }
   ],
   "source": [
    "dataset = NumberSumDataset(data_range=(1,100))\n",
    "\n",
    "print(dataset.__len__())\n",
    "for i in range(5):\n",
    "    # print(next(iter(dataset)))\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1ee9d1-e9e4-4e6d-9d9f-4d3d70407609",
   "metadata": {},
   "source": [
    "Define a simple \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7164cf2-da22-494d-b0b1-44e22dbf28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden = nn.Linear(input_size, 128)\n",
    "        self.output = nn.Linear(128, 1)\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.softmax = nn.Softmax(dim=0)\n",
    "        return\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ece20-1921-4e42-960b-c4875d10585d",
   "metadata": {},
   "source": [
    "Instantiate components needed for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "242da7b0-8b95-4530-8402-5ff5d52895de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NumberSumDataset(data_range=(0,100))\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=100, shuffle=True)\n",
    "model = MLP(input_size=2)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb9be3-5a21-4ed3-b6fd-2d9900898896",
   "metadata": {},
   "source": [
    "Create a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fef191-439c-4eb3-adb7-504b4a314a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Sum of Batch Loss: 291285.17354\n",
      "Epoch 1: Sum of Batch Loss: 7855.38131\n",
      "Epoch 2: Sum of Batch Loss: 1005.95261\n",
      "Epoch 3: Sum of Batch Loss: 43.83301\n",
      "Epoch 4: Sum of Batch Loss: 19.75632\n",
      "Epoch 5: Sum of Batch Loss: 11.46027\n",
      "Epoch 6: Sum of Batch Loss: 7.60782\n",
      "Epoch 7: Sum of Batch Loss: 5.72906\n",
      "Epoch 8: Sum of Batch Loss: 3.56152\n",
      "Epoch 9: Sum of Batch Loss: 2.05779\n",
      "Epoch 10: Sum of Batch Loss: 1.88450\n",
      "Epoch 11: Sum of Batch Loss: 1.81295\n",
      "Epoch 12: Sum of Batch Loss: 1.75916\n",
      "Epoch 13: Sum of Batch Loss: 1.68918\n",
      "Epoch 14: Sum of Batch Loss: 1.62608\n",
      "Epoch 15: Sum of Batch Loss: 1.56905\n",
      "Epoch 16: Sum of Batch Loss: 1.50384\n",
      "Epoch 17: Sum of Batch Loss: 1.44078\n",
      "Epoch 18: Sum of Batch Loss: 1.38032\n",
      "Epoch 19: Sum of Batch Loss: 1.33054\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    total_loss = 0.0\n",
    "    # Iterate over the batches\n",
    "    for X, Y in dataloader:\n",
    "        # Computer model output\n",
    "        preds = model(X)\n",
    "        # Compute the loss\n",
    "        loss = loss_function(preds, Y)\n",
    "        # Backpropogation\n",
    "        loss.backward()\n",
    "        # Update the params\n",
    "        optimizer.step()\n",
    "        # Zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Add the loss of this batch\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch}: Sum of Batch Loss: {total_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467f38a0-a9fe-4d3b-b9e2-1615ecea7210",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9e0d3b-9613-4cc6-a40c-ed1f6eaa67ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.093177795410156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0, X1 = 3.0, 7.0\n",
    "print(model(torch.tensor([X0, X1])).item())\n",
    "7+3 == model(torch.tensor([X0, X1])).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00362894-3f82-4138-aea4-249feb62d304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ud_gen",
   "language": "python",
   "name": "venv_ud_gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
