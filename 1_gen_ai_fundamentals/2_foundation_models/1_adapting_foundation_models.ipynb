{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapting Foundation Models\n",
    "\n",
    "Adaptation in AI is a crucial step to enhance the capabilities of foundation models, allowing them to cater to specific tasks and domains. This process is about tailoring pre-trained AI systems with new data, ensuring they perform optimally in specialized applications and respect privacy constraints. Reaping the benefits of adaptation leads to AI models that are not only versatile but also more aligned with the unique needs of organizations and industries.\n",
    "\n",
    "<img src=\"img/img_12.png\">\n",
    "\n",
    "**Technical terms explained:**\n",
    "* **Fine-tuning**: This is a technique in machine learning where an already trained model is further trained (or tuned) on a new, typically smaller, dataset for better performance on a specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why We Need to Adapt Foundation Models\n",
    "\n",
    "Adapting foundation models is essential due to their limitations in specific areas despite their extensive training on large datasets. Although they excel at many tasks, these models can sometimes misconstrue questions or lack up-to-date information, which highlights the need for fine-tuning. By addressing these weaknesses through additional training or other techniques, the performance of foundation models can be significantly improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) is a powerful approach for keeping Generative AI models informed with the most recent data, particularly when dealing with domain-specific questions. It cleverly combines the comprehensive understanding capacity of a large language model (LLM) with the most up-to-date information pulled from a database of relevant text snippets. The beauty of this system is in its ability to ensure that responses remain accurate and reflective of the latest developments.\n",
    "\n",
    "<img src=\"img/img_13.png\">\n",
    "\n",
    "**Technical Terms:**\n",
    "* **Semantic-embedding**: A representation of text in a high-dimensional space where distances between points correspond to semantic similarity. Phrases with similar meanings are closer together.\n",
    "* **Cosine similarity**: A metric used to measure how similar two vectors are, typically used in the context of semantic embeddings to assess similarity of meanings.\n",
    "* **Vector databases**: Specialized databases designed to store and handle vector data, often employed for facilitating fast and efficient similarity searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Design Techniques\n",
    "\n",
    "Prompt Design Techniques are innovative strategies for tailoring AI foundation models to specific tasks, fostering better performance in various domains. These methods enable us to guide the AI's output by carefully constructing the prompts we provide, enhancing the model's relevance and efficiency in generating responses.\n",
    "\n",
    "1. Prompt tuning: customizing templates to guide a model's predictions in a domain specific task, often involves what words define concepts and where they are placed in the overall structure of the prompt, e.g., placing a question at the end of a prompt is often associated with better results\n",
    "2. Few Shot Prompting: provide a handfull of examples to help guide the model's predictions, e.g., if we want the model to answer a mathematics problem, we can include a few examples of math problems with their solutions\n",
    "3. Zero-Shot Prompting: allow the foundation model to handle a task without any task-specfic examples in the prompt, e.g., \"what is the weather tomorrow\" instead of \"what is the weather tomorrow, for example, last Tuesday was rainy with low of 30\"\n",
    "4. In-Context Learning: allow the model to learn from the context provided in the prompt. There are two forms this may occur:\n",
    "* Provide instructions in the prompt\n",
    "* Provide examples in the prompt\n",
    "5. Chain of Thought (CoT): Provide a series of steps the model can consider to solve a complex task, e.g., provide the steps used to answer a math problem that the model may be able to *consider* and *follow*; you may even just say \"think in steps\" for encouraging the model to use a CoT approach instead of you laying out the steps\n",
    "\n",
    "**Technical Term Explanations:**\n",
    "* **Domain-Specific Task**: A task that is specialized or relevant to a particular area of knowledge or industry, often requiring tailored AI responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prompt Tuning\n",
    "\n",
    "Prompt tuning is a technique in generative AI which allows models to target specific tasks effectively. By crafting prompts, whether through a hands-on approach with hard prompts or through an automated process with soft prompts, we enhance the model's predictive capabilities.\n",
    "\n",
    "**Technical Terms Defined**:\n",
    "* **Prompt**: In AI, a prompt is an input given to the model to generate a specific response or output.\n",
    "* **Prompt Tuning**: This is a method to improve AI models by optimizing prompts so that the model produces better results for specific tasks.\n",
    "* **Hard Prompt**: A manually created template used to guide an AI model's predictions. It requires human ingenuity to craft effective prompts.\n",
    "* **Soft Prompt**: A series of tokens or embeddings optimized through deep learning to help guide model predictions, without necessarily making sense to humans\n",
    "> * A Soft prompt may appear to people as gibberish, but because it takes advantage of the way in which the model is designed, it can be associated with superior outcomes\n",
    "\n",
    "<img src=\"img/img_14.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. One and Few-Shot Prompting\n",
    "\n",
    "One and few-shot prompting represent cutting-edge techniques that enable AI to adapt and perform tasks with minimal instructions. Instead of relying on extensive databases for learning, these methods guide generative AI through just one or a few examples, streamlining the learning process and demonstrating its ability to generalize solutions to new problems. This innovative approach marks a significant advancement in machine learning, empowering AI to quickly adjust to specialized tasks and showcasing the incredible potential for efficiency in teaching AI new concepts.\n",
    "\n",
    "**Technical Terms Explained:**\n",
    "* **One-shot prompting**: Giving an AI model a single example to learn from before it attempts a similar task.\n",
    "* **Few-shot prompting**: Providing an AI model with a small set of examples, such as five or fewer, from which it can learn to generalize and perform tasks.\n",
    "\n",
    "**One Shot Prompt Example:**\n",
    "```\n",
    "Q: What is (25+1)*2?\n",
    "A: The calculation is simple. You add 25 to another 1, which equals 26. Then, you multiply26 by 2, which equals 52. So, (25+1)*2 is 52.\n",
    "\n",
    "Q: What is (3+2)*2?\n",
    "___\n",
    "```\n",
    "\n",
    "**Few Shot Prompt Example:**\n",
    "```\n",
    "1. Q: What is the capital of France?\n",
    "A: Paris\n",
    "2. Q: What is the capital of Peru?\n",
    "A: Lima\n",
    "3. Q: What is the capital of the Phillippines?\n",
    "A: Manila\n",
    "4. Q: What is the capital of Algeria?\n",
    "___\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Zero-Shot Prompting to Classify a Legal Document\n",
    "\n",
    "Zero-shot prompting is a remarkable technique where a generative AI model can take on new tasks without the need for specific training examples. This process leverages the AI's extensive pre-existing knowledge gained from learning patterns across vast datasets. It empowers the AI to infer and generalize effectively to provide answers and solutions in contexts that were not expressly covered during its initial training.\n",
    "\n",
    "**Technical Terms Explained:**\n",
    "* **Zero-shot prompting**: This refers to the capability of an AI model to correctly respond to a prompt or question it hasn't explicitly been trained to answer, relying solely on its prior knowledge and training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. In-Context Learning\n",
    "\n",
    "When performing few-shot, one-shot, or zero-shot learning, we can pass information to the model within the prompt in the form of examples, descriptions, or other data. When we rely on a model using information from within the prompt itself instead of relying on what is stored within its own parameters we are using in-context learning.\n",
    "\n",
    "As these AI models grow in size, their ability to absorb and use in-context information significantly improves, showcasing their potential to adapt to various tasks effectively. The progress in this field is inspiring, as these advances hint at an exciting future where such models could be even more intuitive and useful.\n",
    "\n",
    "<img src=\"img/img_15.png\">\n",
    "\n",
    "<img src=\"img/img_16.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-Thought Prompting is a vital technique for enhancing the reasoning capabilities of large language models by breaking down complex problems into intermediate steps that lead to a solution. By providing models with a line of reasoning, they can more effectively tackle problems that require more advanced problem-solving processes, enabling them to deduce information, such as the number of cookies in a box, after considering all variables.\n",
    "\n",
    "**Technical Terms Explained:**\n",
    "* **Chain-of-Thought Prompting**: A method of guiding a language model through a step-by-step reasoning process to help it solve complex tasks by explicitly detailing the logic needed to reach a conclusion.\n",
    "\n",
    "Prompt Example WITHOUT CoT:\n",
    "```\n",
    "Problem: A baker bakes 60 cookies. She sells 15 of them to a customer and then packs the rest equally into 5 boxes. How many cookies are in each box?\n",
    "\n",
    "Answer: 9 cookies\n",
    "\n",
    "Problem: A baker bakes 30 cookies. Five of them are burnt. She sells 15 of them to a customer and then packs the rest equally into 5 boxes. How many cookies are in each box?\n",
    "___\n",
    "```\n",
    "\n",
    "Prompt Example WITH CoT:\n",
    "```\n",
    "Problem: A baker bakes 60 cookies. She sells 15 of them to a customer and then packs the rest equally into 5 boxes. How many cookies are in each box?\n",
    "\n",
    "Answer:\n",
    "1. Start with the total number of cookies, which is 60.\n",
    "2. Subtract the number of cookies sold to the customer, 15, from the total.\n",
    "3. Calculate the remaining cookies: 60 - 15 = 45 cookies.\n",
    "4. Divide the reamining cookies equally into 5 boxes.\n",
    "5. To find out how many cookies are in each box: 45 / 5 = 9 cookies\n",
    "\n",
    "Problem: A baker bakes 30 cookies. Five of them are burnt. She sells 15 of them to a customer and then packs the rest equally into 5 boxes. How many cookies are in each box?\n",
    "___\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
