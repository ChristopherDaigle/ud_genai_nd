{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapting Foundation Models\n",
    "\n",
    "Adaptation in AI is a crucial step to enhance the capabilities of foundation models, allowing them to cater to specific tasks and domains. This process is about tailoring pre-trained AI systems with new data, ensuring they perform optimally in specialized applications and respect privacy constraints. Reaping the benefits of adaptation leads to AI models that are not only versatile but also more aligned with the unique needs of organizations and industries.\n",
    "\n",
    "<img src=\"img/img_12.png\">\n",
    "\n",
    "**Technical terms explained:**\n",
    "* **Fine-tuning**: This is a technique in machine learning where an already trained model is further trained (or tuned) on a new, typically smaller, dataset for better performance on a specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why We Need to Adapt Foundation Models\n",
    "\n",
    "Adapting foundation models is essential due to their limitations in specific areas despite their extensive training on large datasets. Although they excel at many tasks, these models can sometimes misconstrue questions or lack up-to-date information, which highlights the need for fine-tuning. By addressing these weaknesses through additional training or other techniques, the performance of foundation models can be significantly improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) is a powerful approach for keeping Generative AI models informed with the most recent data, particularly when dealing with domain-specific questions. It cleverly combines the comprehensive understanding capacity of a large language model (LLM) with the most up-to-date information pulled from a database of relevant text snippets. The beauty of this system is in its ability to ensure that responses remain accurate and reflective of the latest developments.\n",
    "\n",
    "<img src=\"img/img_13.png\">\n",
    "\n",
    "**Technical Terms:**\n",
    "* **Semantic-embedding**: A representation of text in a high-dimensional space where distances between points correspond to semantic similarity. Phrases with similar meanings are closer together.\n",
    "* **Cosine similarity**: A metric used to measure how similar two vectors are, typically used in the context of semantic embeddings to assess similarity of meanings.\n",
    "* **Vector databases**: Specialized databases designed to store and handle vector data, often employed for facilitating fast and efficient similarity searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Design Techniques\n",
    "\n",
    "Prompt Design Techniques are innovative strategies for tailoring AI foundation models to specific tasks, fostering better performance in various domains. These methods enable us to guide the AI's output by carefully constructing the prompts we provide, enhancing the model's relevance and efficiency in generating responses.\n",
    "\n",
    "1. Prompt tuning: customizing templates to guide a model's predictions in a domain specific task, often involves what words define concepts and where they are placed in the overall structure of the prompt, e.g., placing a question at the end of a prompt is often associated with better results\n",
    "2. Few Shot Prompting: provide a handfull of examples to help guide the model's predictions, e.g., if we want the model to answer a mathematics problem, we can include a few examples of math problems with their solutions\n",
    "3. Zero-Shot Prompting: allow the foundation model to handle a task without any task-specfic examples in the prompt, e.g., \"what is the weather tomorrow\" instead of \"what is the weather tomorrow, for example, last Tuesday was rainy with low of 30\"\n",
    "4. In-Context Learning: allow the model to learn from the context provided in the prompt. There are two forms this may occur:\n",
    "* Provide instructions in the prompt\n",
    "* Provide examples in the prompt\n",
    "5. Chain of Thought (CoT): Provide a series of steps the model can consider to solve a complex task, e.g., provide the steps used to answer a math problem that the model may be able to *consider* and *follow*; you may even just say \"think in steps\" for encouraging the model to use a CoT approach instead of you laying out the steps\n",
    "\n",
    "**Technical Term Explanations:**\n",
    "* **Domain-Specific Task**: A task that is specialized or relevant to a particular area of knowledge or industry, often requiring tailored AI responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prompt Tuning\n",
    "\n",
    "Prompt tuning is a technique in generative AI which allows models to target specific tasks effectively. By crafting prompts, whether through a hands-on approach with hard prompts or through an automated process with soft prompts, we enhance the model's predictive capabilities.\n",
    "\n",
    "**Technical Terms Defined**:\n",
    "* **Prompt**: In AI, a prompt is an input given to the model to generate a specific response or output.\n",
    "* **Prompt Tuning**: This is a method to improve AI models by optimizing prompts so that the model produces better results for specific tasks.\n",
    "* **Hard Prompt**: A manually created template used to guide an AI model's predictions. It requires human ingenuity to craft effective prompts.\n",
    "* **Soft Prompt**: A series of tokens or embeddings optimized through deep learning to help guide model predictions, without necessarily making sense to humans\n",
    "> * A Soft prompt may appear to people as gibberish, but because it takes advantage of the way in which the model is designed, it can be associated with superior outcomes\n",
    "\n",
    "<img src=\"img/img_14.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. One and Few-Shot Prompting\n",
    "\n",
    "One and few-shot prompting represent cutting-edge techniques that enable AI to adapt and perform tasks with minimal instructions. Instead of relying on extensive databases for learning, these methods guide generative AI through just one or a few examples, streamlining the learning process and demonstrating its ability to generalize solutions to new problems. This innovative approach marks a significant advancement in machine learning, empowering AI to quickly adjust to specialized tasks and showcasing the incredible potential for efficiency in teaching AI new concepts.\n",
    "\n",
    "**Technical Terms Explained:**\n",
    "* **One-shot prompting**: Giving an AI model a single example to learn from before it attempts a similar task.\n",
    "* **Few-shot prompting**: Providing an AI model with a small set of examples, such as five or fewer, from which it can learn to generalize and perform tasks.\n",
    "\n",
    "**One Shot Prompt Example:**\n",
    "```\n",
    "Q: What is (25+1)*2?\n",
    "A: The calculation is simple. You add 25 to another 1, which equals 26. Then, you multiply26 by 2, which equals 52. So, (25+1)*2 is 52.\n",
    "\n",
    "Q: What is (3+2)*2?\n",
    "___\n",
    "```\n",
    "\n",
    "**Few Shot Prompt Example:**\n",
    "```\n",
    "1. Q: What is the capital of France?\n",
    "A: Paris\n",
    "2. Q: What is the capital of Peru?\n",
    "A: Lima\n",
    "3. Q: What is the capital of the Phillippines?\n",
    "A: Manila\n",
    "4. Q: What is the capital of Algeria?\n",
    "___\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Zero-Shot Prompting to Classify a Legal Document\n",
    "\n",
    "Zero-shot prompting is a remarkable technique where a generative AI model can take on new tasks without the need for specific training examples. This process leverages the AI's extensive pre-existing knowledge gained from learning patterns across vast datasets. It empowers the AI to infer and generalize effectively to provide answers and solutions in contexts that were not expressly covered during its initial training.\n",
    "\n",
    "**Technical Terms Explained:**\n",
    "* **Zero-shot prompting**: This refers to the capability of an AI model to correctly respond to a prompt or question it hasn't explicitly been trained to answer, relying solely on its prior knowledge and training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. In-Context Learning\n",
    "\n",
    "When performing few-shot, one-shot, or zero-shot learning, we can pass information to the model within the prompt in the form of examples, descriptions, or other data. When we rely on a model using information from within the prompt itself instead of relying on what is stored within its own parameters we are using in-context learning.\n",
    "\n",
    "As these AI models grow in size, their ability to absorb and use in-context information significantly improves, showcasing their potential to adapt to various tasks effectively. The progress in this field is inspiring, as these advances hint at an exciting future where such models could be even more intuitive and useful.\n",
    "\n",
    "<img src=\"img/img_15.png\">\n",
    "\n",
    "<img src=\"img/img_16.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chain-of-Thought Prompting\n",
    "\n",
    "Chain-of-Thought Prompting is a vital technique for enhancing the reasoning capabilities of large language models by breaking down complex problems into intermediate steps that lead to a solution. By providing models with a line of reasoning, they can more effectively tackle problems that require more advanced problem-solving processes, enabling them to deduce information, such as the number of cookies in a box, after considering all variables.\n",
    "\n",
    "**Technical Terms Explained:**\n",
    "* **Chain-of-Thought Prompting**: A method of guiding a language model through a step-by-step reasoning process to help it solve complex tasks by explicitly detailing the logic needed to reach a conclusion.\n",
    "\n",
    "Prompt Example WITHOUT CoT:\n",
    "```\n",
    "Problem: A baker bakes 60 cookies. She sells 15 of them to a customer and then packs the rest equally into 5 boxes. How many cookies are in each box?\n",
    "\n",
    "Answer: 9 cookies\n",
    "\n",
    "Problem: A baker bakes 30 cookies. Five of them are burnt. She sells 15 of them to a customer and then packs the rest equally into 5 boxes. How many cookies are in each box?\n",
    "___\n",
    "```\n",
    "\n",
    "Prompt Example WITH CoT:\n",
    "```\n",
    "Problem: A baker bakes 60 cookies. She sells 15 of them to a customer and then packs the rest equally into 5 boxes. How many cookies are in each box?\n",
    "\n",
    "Answer:\n",
    "1. Start with the total number of cookies, which is 60.\n",
    "2. Subtract the number of cookies sold to the customer, 15, from the total.\n",
    "3. Calculate the remaining cookies: 60 - 15 = 45 cookies.\n",
    "4. Divide the reamining cookies equally into 5 boxes.\n",
    "5. To find out how many cookies are in each box: 45 / 5 = 9 cookies\n",
    "\n",
    "Problem: A baker bakes 30 cookies. Five of them are burnt. She sells 15 of them to a customer and then packs the rest equally into 5 boxes. How many cookies are in each box?\n",
    "___\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Using Probing to TRain A Classifier\n",
    "\n",
    "Using probing to train a classifier is a powerful approach to tailor generative AI foundation models, like BERT, for specific applications. By adding a modestly-sized neural network, known as a classification head, to a foundation model, one can specialize in particular tasks such as sentiment analysis. This technique involves freezing the original model's parameters and only adjusting the classification head through training with labeled data. Ultimately, this process simplifies adapting sophisticated AI systems to our needs, providing a practical tool for developing efficient and targeted machine learning solutions.\n",
    "\n",
    "**Technical Terms Explained:**\n",
    "* **Probing**: This is a method of examining what information is contained in different parts of a machine learning model.\n",
    "* **Linear Probing**: A simple form of probing that involves attaching a linear classifier to a pre-trained model to adapt it to a new task without modifying the original model.\n",
    "* **Classification Head**: It is the part of a neural network that is tailored to classify input data into defined categories.\n",
    "\n",
    "<img src=\"img/img_17.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Create a BERT sentiment classifier\n",
    "\n",
    "In this exercise, you will create a BERT sentiment classifier (actually DistilBERT) using the [Hugging Face Transformers](https://huggingface.co/transformers/) library. \n",
    "\n",
    "You will use the [IMDB movie review dataset](https://huggingface.co/datasets/imdb) to train and evaluate your model. The IMDB dataset contains movie reviews that are labeled as either positive or negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==3.2.0 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (3.2.0)\n",
      "Collecting huggingface_hub==0.28.1\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (3.11.11)\n",
      "Requirement already satisfied: packaging in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from datasets==3.2.0) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from huggingface_hub==0.28.1) (4.11.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from aiohttp->datasets==3.2.0) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from aiohttp->datasets==3.2.0) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from aiohttp->datasets==3.2.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from aiohttp->datasets==3.2.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from aiohttp->datasets==3.2.0) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from aiohttp->datasets==3.2.0) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.2.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.2.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.2.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.2.0) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from pandas->datasets==3.2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from pandas->datasets==3.2.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from pandas->datasets==3.2.0) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.16.0)\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.26.5\n",
      "    Uninstalling huggingface-hub-0.26.5:\n",
      "      Successfully uninstalled huggingface-hub-0.26.5\n",
      "Successfully installed huggingface_hub-0.28.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# You will need to choose \"Kernel -> Restart Kernel\" from the menu after executing this cell\n",
    "%pip install datasets==3.2.0 huggingface_hub==0.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the datasets\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 500\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 500\n",
       " })}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the train and test splits of the imdb dataset\n",
    "splits = [\"train\", \"test\"]\n",
    "ds = {split: ds for split, ds in zip(splits, load_dataset(\"imdb\", split=splits))}\n",
    "\n",
    "# Thin out the dataset to make it run faster for this example\n",
    "for split in splits:\n",
    "    ds[split] = ds[split].shuffle(seed=42).select(range(500))\n",
    "\n",
    "# Show the dataset\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process datasets\n",
    "\n",
    "Now we are going to process our datasets by converting all the text into tokens for our models. You may ask, why isn't the text converted already? Well, different models may use different tokenizers, so by converting at train time we retain more flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9e59c6db3343f9b586e1896a48e079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6274dd544443539e9401b0fe417e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2045, 2003, 2053, 7189, 2012, 2035, 2090, 3481, 3771, 1998, 6337, 2099, 2021, 1996, 2755, 2008, 2119, 2024, 2610, 2186, 2055, 6355, 6997, 1012, 6337, 2099, 3504, 15594, 2100, 1010, 3481, 3771, 3504, 4438, 1012, 6337, 2099, 14811, 2024, 3243, 3722, 1012, 3481, 3771, 1005, 1055, 5436, 2024, 2521, 2062, 8552, 1012, 1012, 1012, 3481, 3771, 3504, 2062, 2066, 3539, 8343, 1010, 2065, 2057, 2031, 2000, 3962, 12319, 1012, 1012, 1012, 1996, 2364, 2839, 2003, 5410, 1998, 6881, 2080, 1010, 2021, 2031, 1000, 17936, 6767, 7054, 3401, 1000, 1012, 2111, 2066, 2000, 12826, 1010, 2000, 3648, 1010, 2000, 16157, 1012, 2129, 2055, 2074, 9107, 1029, 6057, 2518, 2205, 1010, 2111, 3015, 3481, 3771, 3504, 2137, 2021, 1010, 2006, 1996, 2060, 2192, 1010, 9177, 2027, 9544, 2137, 2186, 1006, 999, 999, 999, 1007, 1012, 2672, 2009, 1005, 1055, 1996, 2653, 1010, 2030, 1996, 4382, 1010, 2021, 1045, 2228, 2023, 2186, 2003, 2062, 2394, 2084, 2137, 1012, 2011, 1996, 2126, 1010, 1996, 5889, 2024, 2428, 2204, 1998, 6057, 1012, 1996, 3772, 2003, 2025, 23105, 2012, 2035, 1012, 1012, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> with your code that constructs a query to send to the LLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Preprocess the imdb dataset by returning tokenized examples.\"\"\"\n",
    "    # <MASK>\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_ds = {}\n",
    "for split in splits:\n",
    "    tokenized_ds[split] = ds[split].map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "# Check that we tokenized the examples properly\n",
    "assert tokenized_ds[\"train\"][0][\"input_ids\"][:5] == [101, 2045, 2003, 2053, 7189]\n",
    "\n",
    "# Show the first example of the tokenized training set\n",
    "print(tokenized_ds[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and set up the model\n",
    "\n",
    "We will now load the model and freeze most of the parameters of the model: everything except the classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=2, bias=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace <MASK> with your code freezes the base model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},  # For converting predictions to strings\n",
    "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1},\n",
    ")\n",
    "\n",
    "# Freeze all the parameters of the base model\n",
    "# Hint: Check the documentation at https://huggingface.co/transformers/v4.2.2/training.html\n",
    "for param in model.base_model.parameters():\n",
    "    # <MASK>\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train it!\n",
    "\n",
    "Now it's time to train our model. We'll use the `Trainer` class from the ðŸ¤— Transformers library to do this. The `Trainer` class provides a high-level API that abstracts away a lot of the training loop.\n",
    "\n",
    "First we'll define a function to compute our accuracy metric then we make the `Trainer`.\n",
    "\n",
    "Let's take this opportunity to learn about the `DataCollator`. According to the HuggingFace documentation:\n",
    "\n",
    "> Data collators are objects that will form a batch by using a list of dataset elements as input. These elements are of the same type as the elements of train_dataset or eval_dataset.\n",
    "\n",
    "> To be able to build batches, data collators may apply some processing (like padding).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/8z/8jf5n46j4mgcn25c47w2wxrr0000gn/T/ipykernel_57905/3983437982.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.484688</td>\n",
       "      <td>0.818000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=0.525149169921875, metrics={'train_runtime': 14.1793, 'train_samples_per_second': 35.263, 'train_steps_per_second': 8.816, 'total_flos': 66233699328000.0, 'train_loss': 0.525149169921875, 'epoch': 1.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace <MASK> with your DataCollatorWithPadding argument(s)\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "\n",
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/sentiment_analysis\",\n",
    "        learning_rate=2e-3,\n",
    "        # Reduce the batch size if you don't have enough memory\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=1,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    # data_collator=DataCollatorWithPadding(<MASK>),\n",
    "    data_collator=DataCollatorWithPadding(tokenizer = tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Evaluating the model is as simple as calling the evaluate method on the trainer object. This will run the model on the test set and compute the metrics we specified in the compute_metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4612870216369629,\n",
       " 'eval_accuracy': 0.802,\n",
       " 'eval_runtime': 6.3511,\n",
       " 'eval_samples_per_second': 78.727,\n",
       " 'eval_steps_per_second': 19.682,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the performance of the model on the test set\n",
    "# What do you think the evaluation accuracy will be?\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the results\n",
    "\n",
    "Let's look at two examples with labels and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I unsuspectedly rented A Thousand Acres...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is the latest entry in the long series of...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  predicted_label\n",
       "0    When I unsuspectedly rented A Thousand Acres...      1                1\n",
       "1  This is the latest entry in the long series of...      1                1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tokenized_ds[\"test\"])\n",
    "df = df[[\"text\", \"label\"]]\n",
    "\n",
    "# Replace <br /> tags in the text with spaces\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"<br />\", \" \")\n",
    "\n",
    "# Add the model predictions to the dataframe\n",
    "predictions = trainer.predict(tokenized_ds[\"test\"])\n",
    "df[\"predicted_label\"] = np.argmax(predictions[0], axis=1)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.2\n"
     ]
    }
   ],
   "source": [
    "df['correct'] = df['label'] == df['predicted_label']\n",
    "print(f\"Accuracy: {round(sum(df['correct']/df.shape[0]),5)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at some of the incorrect predictions\n",
    "\n",
    "Let's take a look at some of the incorrectly-predcted examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Don't pay any attention to the rave reviews of this film here. It is the worst Van Damme film and one of the worst of any sort I have ever seen. It would appeal to somebody with no depth whatever who requires nothing more than gunfire and explosions to be entertained.  Seeing that this is directed by Peter Hyams it has made me realise that Peter has no talent as a director, but is very good at filming explosions and the like. However, movies need other elements as well; for example, a story. This one didn't have one. This might explain the awfulness of some of Mr. Hyams' more recent films, hardly any better than this one, really.  One can't help wondering how some people ever were put behind a camera.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Coming from Kiarostami, this art-house visual and sound exposition is a surprise. For a director known for his narratives and keen observation of humans, especially children, this excursion into minimalist cinematography begs for questions: Why did he do it? Was it to keep him busy during a vacation at the shore?   \"Five, 5 Long Takes\" consists of, you guessed it, five long takes. They are (the title names are my own and the times approximate):   \"Driftwood and waves\". The camera stands nearly still looking at a small piece of driftwood as it gets moved around by small waves splashing on a beach. Ten minutes.  \"Watching people on the boardwalk\". The camera stands still looking at the ocean horizon and a boardwalk. People walk across the camera frame, their faces too far and blurry to make them interesting. Eleven minutes.  \"Six dogs at the water's edge\". The camera stands still looking at the ocean horizon with a sandy stretch of beach nearby. Far away at the water's edge, six dogs not doing much, just relaxing. Sixteen minutes.  \"Ducks in line, gaggle of ducks\". The camera stands still looking at the ocean horizon near the water's edge. Dozen and dozen of ducks stream in single file from left to right. I assume that Kiarostami released them gradually. The last two ducks stop dead on their track and suddenly a gaggle of ducks rolls quietly from right to left. I assume Kiarostami collected the ducks and re-released all at the same time. It is not the first time that he deals with the contrast between organized and disorganized behavior. Eight minutes.  \"Frog symphony, oops, I mean cacophony, for a stormy night\". The camera stands over a pond at night. It's pitch black except for what appears to be the reflection of the moon on the undulating water. It is a stormy night and clouds race to cover the moon. The screen goes dark. What remains for us is the cacophony of frogs, howling dogs and, eventually, morning roosters. Hit me on the head if this was done in a single take. I saw this segment as a sound composition put together in the editing room and accompanied by a simple visualization. Twenty seven minutes!   Except for the mildly amusing ducks, this exercise in minimalism left me cold. A nonessential film for Kiarostami admirers.  I thought I would rate \"Five\" a five, but four is what it deserves.  The film is dedicated to Yasujiru Ozu.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text  \\\n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Don't pay any attention to the rave reviews of this film here. It is the worst Van Damme film and one of the worst of any sort I have ever seen. It would appeal to somebody with no depth whatever who requires nothing more than gunfire and explosions to be entertained.  Seeing that this is directed by Peter Hyams it has made me realise that Peter has no talent as a director, but is very good at filming explosions and the like. However, movies need other elements as well; for example, a story. This one didn't have one. This might explain the awfulness of some of Mr. Hyams' more recent films, hardly any better than this one, really.  One can't help wondering how some people ever were put behind a camera.   \n",
       "21  Coming from Kiarostami, this art-house visual and sound exposition is a surprise. For a director known for his narratives and keen observation of humans, especially children, this excursion into minimalist cinematography begs for questions: Why did he do it? Was it to keep him busy during a vacation at the shore?   \"Five, 5 Long Takes\" consists of, you guessed it, five long takes. They are (the title names are my own and the times approximate):   \"Driftwood and waves\". The camera stands nearly still looking at a small piece of driftwood as it gets moved around by small waves splashing on a beach. Ten minutes.  \"Watching people on the boardwalk\". The camera stands still looking at the ocean horizon and a boardwalk. People walk across the camera frame, their faces too far and blurry to make them interesting. Eleven minutes.  \"Six dogs at the water's edge\". The camera stands still looking at the ocean horizon with a sandy stretch of beach nearby. Far away at the water's edge, six dogs not doing much, just relaxing. Sixteen minutes.  \"Ducks in line, gaggle of ducks\". The camera stands still looking at the ocean horizon near the water's edge. Dozen and dozen of ducks stream in single file from left to right. I assume that Kiarostami released them gradually. The last two ducks stop dead on their track and suddenly a gaggle of ducks rolls quietly from right to left. I assume Kiarostami collected the ducks and re-released all at the same time. It is not the first time that he deals with the contrast between organized and disorganized behavior. Eight minutes.  \"Frog symphony, oops, I mean cacophony, for a stormy night\". The camera stands over a pond at night. It's pitch black except for what appears to be the reflection of the moon on the undulating water. It is a stormy night and clouds race to cover the moon. The screen goes dark. What remains for us is the cacophony of frogs, howling dogs and, eventually, morning roosters. Hit me on the head if this was done in a single take. I saw this segment as a sound composition put together in the editing room and accompanied by a simple visualization. Twenty seven minutes!   Except for the mildly amusing ducks, this exercise in minimalism left me cold. A nonessential film for Kiarostami admirers.  I thought I would rate \"Five\" a five, but four is what it deserves.  The film is dedicated to Yasujiru Ozu.   \n",
       "\n",
       "    label  predicted_label  correct  \n",
       "7       0                1    False  \n",
       "21      0                1    False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show full cell output\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "df[df[\"label\"] != df[\"predicted_label\"]].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning\n",
    "\n",
    "*Fine-tuning* is an important phase in enhancing the abilities of generative AI models, making them adept at specific tasks. By introducing additional data to these powerful models, they can be tailored to meet particular requirements, which is invaluable in making AI more effective and efficient. Although this process comes with its challenges, such as the need for significant computational resources and data, the outcome is a more specialized and capable AI system that can bring value to a wide range of applications.\n",
    "\n",
    "**Technical Terms Explained:**\n",
    "* **Fine-tuning**: This is the process of adjusting a pre-trained model so it performs better on a new, similar task. It's like teaching an experienced doctor a new medical procedure; they're already a doctor, but they're improving their skills in a particular area.\n",
    "* **Catastrophic Forgetting**: This happens when a model learns something new but forgets what it learned before. Imagine if you crammed for a history test and did great, but then forgot most of what you learned when you started studying for a math test.\n",
    "\n",
    "Fine-tuning a pre-trained model is an activity which is a subset of Transfer Learning - model created to perform some general tasks in NLP or CV usually has some number of parameters updated to align it to a more a specific task than on that which it was pre-trained\n",
    "\n",
    "<img src=\"img/img_18.png\">\n",
    "\n",
    "Traditional fine-tuning adjust every parameter in the model. So, a large neural network with many layers would be an intensive task for traditional fine-tuning\n",
    "\n",
    "<img src=\"img/img_19.png\">\n",
    "\n",
    "**Challenges of Traditional Fine-Tuning:**\n",
    "\n",
    "* Gathering of labeled data: the more intensive the task being fine-tuned, the more complex this aspect is\n",
    "* Computational Resources: a potential of the same scale of the original resources used being required (i.e., if it costs 100million GPU to build the first model, it may be necessary to use 100million GPU again just to fine-tune it)\n",
    "* Storage: parameters of the model need to stored for later use that now has defined the new model\n",
    "* Out-of-Distribution Data: challenge of introducing data that is statistically significantly different than the source training data distribution which would then imply the parameters of the model were never aligned to that OOD-Data; the impact of this may be *catastrophic forgetting*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter-Efficient Fine Tuning (PEFT)\n",
    "\n",
    "Parameter-efficient fine-tuning (PEFT) is a technique crucial for adapting large language models more efficiently, with the bonus of not requiring heavy computational power. This approach includes various strategies to update only a small set of parameters, thereby maintaining a balance between model adaptability and resource consumption. The techniques ensure that models can be swiftly deployed in different industrial contexts, considering both time constraints and the necessity for scaling operations efficiently.\n",
    "\n",
    "**Technical Terms Explained:**\n",
    "* **Parameter-efficient fine-tuning (PEFT)**: A method of updating a predefined subset of a model's parameters to tailor it to specific tasks, without the need to modify the entire model, thus saving computational resources.\n",
    "* **Frozen Parameters**: In the context of machine learning, this refers to model parameters that are not changed or updated during the process of training or fine-tuning.\n",
    "* **Low-Rank Adaptation (LoRA)**: A technique where a large matrix is approximated using two smaller matrices, greatly reducing the number of parameters that need to be trained during fine-tuning.\n",
    "* **Adapters**: Additional model components inserted at various layers; only the parameters of these adapters are trained, not of the entire model.\n",
    "\n",
    "In PEFT scenarios, we may choose to freeze all the layers in the model except the last or last and second to last layers\n",
    "<img src=\"img/img_20.png\">\n",
    "\n",
    "LoRA: In Low-Rank Adaptation, we focs on one (or a few) layers and freeze the rest, we then use the outcome of the prior layers to update a decomposed representation, a lower rank (i.e., less linearly dependent columns/variables/parameters), of the original layer\n",
    "<img src=\"img/img_21.png\">\n",
    "\n",
    "Note the two matrices, B and A, which together reproduce (at least approximately) the original pretrained weights, but also note that these B and A together have combined less parameters than the original pretrained weights:\n",
    "<img src=\"img/img_22.png\">\n",
    "\n",
    "Here is how the matrix demonposition of the original weights can either reproduce or improve the the original weights to our task which we are finetuning:\n",
    "<img src=\"img/img_23.png\">\n",
    "\n",
    "Adapters: sometimes we want to additional components to a model and ONLY update the parameters of those additional components. These adapters can be inserted to the original model at different layers and the weights of the original model can be frozen while the adapters are trained (i.e., LoRA is an example of an adapter)\n",
    "<img src=\"img/img_24.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Full Fine-tuning BERT\n",
    "\n",
    "In this exercise, you will create a **BERT-based text classifier** (actually **DistilBERT**) using the [Hugging Face Transformers](https://huggingface.co/transformers/) library. You will perform **full fine-tuning** on the **SMS Spam dataset** from the [datasets](https://huggingface.co/docs/datasets/) package and evaluate your modelâ€™s performance.\n",
    "\n",
    "The **SMS Spam dataset (sms_spam)** contains text messages that are **labeled as either 'ham' (not spam) or 'spam'**, making it a **binary classification problem**. Your goal is to fine-tune a DistilBERT model to accurately classify these messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %! pip install -q \"datasets==2.15.0\"\n",
    "# I am using 3.2.0 in my instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sms', 'label'],\n",
      "    num_rows: 4459\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sms': ['Had your mobile 10 mths? Update to the latest Camera/Video phones for FREE. KEEP UR SAME NUMBER, Get extra free mins/texts. Text YES for a call\\n',\n",
       "  'Like  &lt;#&gt; , same question\\n',\n",
       "  'Should I have picked up a receipt or something earlier\\n',\n",
       "  \"Lovely smell on this bus and it ain't tobacco... \\n\",\n",
       "  'Ok...\\n'],\n",
       " 'label': [1, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sms_spam dataset\n",
    "# See: https://huggingface.co/datasets/sms_spam\n",
    "\n",
    "# The sms_spam dataset only has a train split, so we use the train_test_split method to split it into train and test\n",
    "dataset = load_dataset(\"sms_spam\", split=\"train\").train_test_split(\n",
    "    test_size=0.2, shuffle=True, seed=23\n",
    ")\n",
    "\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "# View the dataset characteristics\n",
    "print(dataset[\"train\"])\n",
    "dataset[\"train\"][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sms': 'Had your mobile 10 mths? Update to the latest Camera/Video phones for FREE. KEEP UR SAME NUMBER, Get extra free mins/texts. Text YES for a call\\n', 'label': 1}\n",
      "{'sms': 'Like  &lt;#&gt; , same question\\n', 'label': 0}\n",
      "{'sms': 'Should I have picked up a receipt or something earlier\\n', 'label': 0}\n",
      "{'sms': \"Lovely smell on this bus and it ain't tobacco... \\n\", 'label': 0}\n",
      "{'sms': 'Ok...\\n', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "# Label == 1 == Spam\n",
    "for i in list(range(5)):\n",
    "    print(dataset[\"train\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process datasets\n",
    "\n",
    "Now we are going to process our datasets by converting all the text into tokens for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39920ee67d2f41578e92d8b01c2070df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4459 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db11140323f4c8ab0129f23f8fa0b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1115 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's use a lambda function to tokenize all the examples\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(\n",
    "        lambda x: tokenizer(x[\"sms\"], truncation=True), batched=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sms', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 4459\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the available columns in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sms', 'Had your mobile 10 mths? Update to the latest Camera/Video phones for FREE. KEEP UR SAME NUMBER, Get extra free mins/texts. Text YES for a call\\n')\n",
      "('label', 1)\n",
      "('input_ids', [101, 2018, 2115, 4684, 2184, 11047, 7898, 1029, 10651, 2000, 1996, 6745, 4950, 1013, 2678, 11640, 2005, 2489, 1012, 2562, 24471, 2168, 2193, 1010, 2131, 4469, 2489, 8117, 2015, 1013, 6981, 1012, 3793, 2748, 2005, 1037, 2655, 102])\n",
      "('attention_mask', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "('sms', 'Like  &lt;#&gt; , same question\\n')\n",
      "('label', 0)\n",
      "('input_ids', [101, 2066, 1004, 8318, 1025, 1001, 1004, 14181, 1025, 1010, 2168, 3160, 102])\n",
      "('attention_mask', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "('sms', 'Should I have picked up a receipt or something earlier\\n')\n",
      "('label', 0)\n",
      "('input_ids', [101, 2323, 1045, 2031, 3856, 2039, 1037, 24306, 2030, 2242, 3041, 102])\n",
      "('attention_mask', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "('sms', \"Lovely smell on this bus and it ain't tobacco... \\n\")\n",
      "('label', 0)\n",
      "('input_ids', [101, 8403, 5437, 2006, 2023, 3902, 1998, 2009, 7110, 1005, 1056, 9098, 1012, 1012, 1012, 102])\n",
      "('attention_mask', [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "\n",
      "('sms', 'Ok...\\n')\n",
      "('label', 0)\n",
      "('input_ids', [101, 7929, 1012, 1012, 1012, 102])\n",
      "('attention_mask', [1, 1, 1, 1, 1, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in list(range(5)):\n",
    "    for elem in tokenized_dataset['train'][i].items():\n",
    "        print(elem)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and set up the model\n",
    "\n",
    "In this case we are doing a full fine tuning, so we will want to unfreeze all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not spam\", 1: \"spam\"},\n",
    "    label2id={\"not spam\": 0, \"spam\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze all the model parameters.\n",
    "# Hint: Check the documentation at https://huggingface.co/transformers/v4.2.2/training.html\n",
    "for param in model.parameters():\n",
    "    # <MASK>\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): DistilBertSdpaAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train it!\n",
    "\n",
    "Now it's time to train our model. We'll use the `Trainer` class.\n",
    "\n",
    "First we'll define a function to compute our accuracy metreic then we make the `Trainer`.\n",
    "\n",
    "In this instance, we will fill in some of the training arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherdaigle/miniconda3/envs/venv_ud_gen/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/8z/8jf5n46j4mgcn25c47w2wxrr0000gn/T/ipykernel_57905/1640058892.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# The HuggingFace Trainer class handles the training and eval loop for PyTorch for us.\n",
    "# Read more about it here https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./data/spam_not_spam\",\n",
    "        # Set the learning rate\n",
    "        # <MASK>\n",
    "        learning_rate = 0.0001,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        # <MASK>\n",
    "        per_device_train_batch_size = 32,\n",
    "        # <MASK>\n",
    "        per_device_eval_batch_size = 32,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        # <MASK>\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        # <MASK>\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='280' max='280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [280/280 01:07, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.037756</td>\n",
       "      <td>0.989238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.042168</td>\n",
       "      <td>0.988341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.1 s, sys: 10.5 s, total: 45.7 s\n",
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=280, training_loss=0.047164722851344515, metrics={'train_runtime': 68.827, 'train_samples_per_second': 129.571, 'train_steps_per_second': 4.068, 'total_flos': 170050624693044.0, 'train_loss': 0.047164722851344515, 'epoch': 2.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Evaluating the model is as simple as calling the evaluate method on the trainer object. This will run the model on the test set and compute the metrics we specified in the compute_metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.03775627911090851,\n",
       " 'eval_accuracy': 0.989237668161435,\n",
       " 'eval_runtime': 2.4929,\n",
       " 'eval_samples_per_second': 447.263,\n",
       " 'eval_steps_per_second': 14.04,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the performance of the model on the test set\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the results\n",
    "\n",
    "Let's look at a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>predictions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yup... Hey then one day on fri we can ask miwa and jiayin take leave go karaoke \\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy new years melody!\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRIVATE! Your 2003 Account Statement for shows 800 un-redeemed S. I. M. points. Call 08715203652 Identifier Code: 42810 Expires 29/10/0\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URGENT! We are trying to contact U. Todays draw shows that you have won a Â£800 prize GUARANTEED. Call 09050003091 from land line. Claim C52. Valid 12hrs only\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had askd u a question some hours before. Its answer\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SMS. ac JSco: Energy is high, but u may not know where 2channel it. 2day ur leadership skills r strong. Psychic? Reply ANS w/question. End? Reply END JSCO\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yun ah.the ubi one say if Ã¼ wan call by tomorrow.call 67441233 look for irene.ere only got bus8,22,65,61,66,382. Ubi cres,ubi tech park.6ph for 1st 5wkg days.Ã¨n\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Burger King - Wanna play footy at a top stadium? Get 2 Burger King before 1st Sept and go Large or Super with Coca-Cola and walk out a winner\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                  sms  \\\n",
       "0                                                                                  Yup... Hey then one day on fri we can ask miwa and jiayin take leave go karaoke \\n   \n",
       "1                                                                                                                                           Happy new years melody!\\n   \n",
       "2                           PRIVATE! Your 2003 Account Statement for shows 800 un-redeemed S. I. M. points. Call 08715203652 Identifier Code: 42810 Expires 29/10/0\\n   \n",
       "3     URGENT! We are trying to contact U. Todays draw shows that you have won a Â£800 prize GUARANTEED. Call 09050003091 from land line. Claim C52. Valid 12hrs only\\n   \n",
       "4                                                                                                             I had askd u a question some hours before. Its answer\\n   \n",
       "5        SMS. ac JSco: Energy is high, but u may not know where 2channel it. 2day ur leadership skills r strong. Psychic? Reply ANS w/question. End? Reply END JSCO\\n   \n",
       "6  Yun ah.the ubi one say if Ã¼ wan call by tomorrow.call 67441233 look for irene.ere only got bus8,22,65,61,66,382. Ubi cres,ubi tech park.6ph for 1st 5wkg days.Ã¨n\\n   \n",
       "7                     Burger King - Wanna play footy at a top stadium? Get 2 Burger King before 1st Sept and go Large or Super with Coca-Cola and walk out a winner\\n   \n",
       "\n",
       "   predictions  labels  \n",
       "0            0       0  \n",
       "1            0       0  \n",
       "2            1       1  \n",
       "3            1       1  \n",
       "4            0       0  \n",
       "5            1       1  \n",
       "6            1       0  \n",
       "7            0       1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe with the predictions and the text and the labels\n",
    "items_for_manual_review = tokenized_dataset[\"test\"].select(\n",
    "    [0, 1, 22, 31, 43, 292, 448, 487]\n",
    ")\n",
    "\n",
    "results = trainer.predict(items_for_manual_review)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"sms\": [item[\"sms\"] for item in items_for_manual_review],\n",
    "        \"predictions\": results.predictions.argmax(axis=1),\n",
    "        \"labels\": results.label_ids,\n",
    "    }\n",
    ")\n",
    "# Show all the cell\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of the exercise\n",
    "\n",
    "Great work! Congrats on making it to the end of the exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dynamic field of Artificial Intelligence, the shift from building models from the ground up to adapting existing foundational models is becoming increasingly prevalent. Mastery of adaptation techniquesâ€”from prompting methods such as few-shot learning and chain-of-thought prompting, to parameter-efficient fine-tuning techniques such as low-rank adaptationâ€”empowers us to leverage pre-existing powerful models for diverse applications, enhancing creativity and efficiency in our projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ud_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
